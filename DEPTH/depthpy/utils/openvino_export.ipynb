{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting models to OpenVINO IR (\"Intermediate Representation\") formats\n",
    "[OpenVINO doc](https://docs.openvino.ai/2021.2/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html)\n",
    "\n",
    "Install OpenVINO: `pip install openvino-dev[onnx,pytorch]`\n",
    "\n",
    "Weirdly, `dpt_hybrid_384.onnx` cannot be converted. I assume the error can be bypassed if it is exported as eval-only, if it's possible (I'm afraid it's not). <br>\n",
    "The v2.1 small 256 has an official OpenVINO format release. <br>\n",
    "\n",
    "Tested:\n",
    "- `dpt_beit_large_512`\n",
    "- `dpt_swin2_large_384`\n",
    "- `dpt_large_384`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "onnxpath = \"../../onnx\"\n",
    "#onnxs = [e for e in os.listdir(onnxpath) if e.endswith(\"onnx\")]\n",
    "#onnxs\n",
    "\n",
    "onnxs = [\"dpt_large_384.onnx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "mo --input_model ../../onnx\\dpt_large_384.onnx --model_name openvino_dpt_large_384 --output_dir ../weights\n",
      "Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2022-3&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: d:\\codes\\DepthViewer\\DEPTH\\depthpy\\weights\\openvino_dpt_large_384.xml\n",
      "[ SUCCESS ] BIN file: d:\\codes\\DepthViewer\\DEPTH\\depthpy\\weights\\openvino_dpt_large_384.bin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "output_dir = \"../weights\"\n",
    "\n",
    "for onnx in onnxs:\n",
    "\tprint('*'*64)\n",
    "\n",
    "\tonnx_abspath = os.path.join(onnxpath, onnx)\n",
    "\t\t\n",
    "\tmodel_name = onnx.replace(\".onnx\", \"\")\n",
    "\tmodel_name = \"openvino_\" + model_name\n",
    "\n",
    "\tcmd = f\"mo --input_model {onnx_abspath} --model_name {model_name} --output_dir {output_dir}\"\n",
    "\tprint(cmd)\n",
    "\n",
    "\t#res = os.system(cmd)\n",
    "\t#print(res)\n",
    "\n",
    "\tres = subprocess.run(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\tprint(res.stdout.decode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
